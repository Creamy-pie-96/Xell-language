#!/usr/bin/env python3
"""
gen_grammar.py — Dynamic grammar generator for Xell
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

Single source of truth: the C++ source files.

Reads:
  - src/lexer/token.hpp      → keywords, operators
  - src/builtins/*.hpp        → builtin function names
  - src/interpreter/interpreter.hpp → runtime info

Generates:
  - Extensions/xell-vscode/syntaxes/xell.tmLanguage.json

Usage:
    python3 Extensions/gen_grammar.py
    python3 Extensions/gen_grammar.py --check   # verify grammar is up-to-date
"""

import re
import json
import sys
import os
from pathlib import Path
from collections import OrderedDict

# ─── Paths ────────────────────────────────────────────────

SCRIPT_DIR = Path(__file__).resolve().parent
ROOT = SCRIPT_DIR.parent
SRC_DIR = ROOT / "src"
TOKEN_HPP = SRC_DIR / "lexer" / "token.hpp"
BUILTINS_DIR = SRC_DIR / "builtins"

VSCODE_DIR = SCRIPT_DIR / "xell-vscode"
TMLANG_OUT = VSCODE_DIR / "syntaxes" / "xell.tmLanguage.json"


# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# 1. EXTRACT DATA FROM C++ HEADERS
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

def read_file(path):
    with open(path, "r") as f:
        return f.read()


def extract_keywords(src):
    """Extract keywords from TokenType enum in token.hpp.
    Looks for entries like FN, GIVE, IF, etc. that map to keywords."""
    keywords = []
    # Match keyword-like enum entries
    keyword_map = {
        "FN": "fn", "GIVE": "give", "IF": "if", "ELIF": "elif",
        "ELSE": "else", "FOR": "for", "WHILE": "while", "IN": "in",
        "BRING": "bring", "FROM": "from", "AS": "as",
        "AND": "and", "OR": "or", "NOT": "not",
        "IS": "is", "EQ": "eq", "NE": "ne", "GT": "gt", "LT": "lt",
        "GE": "ge", "LE": "le", "OF": "of",
        "TRUE_KW": "true", "FALSE_KW": "false", "NONE_KW": "none",
    }
    for enum_name, kw in keyword_map.items():
        if enum_name in src:
            keywords.append(kw)
    return sorted(set(keywords))


def extract_builtins_from_files():
    """Extract builtin function names from src/builtins/ headers."""
    builtins = set()
    if not BUILTINS_DIR.exists():
        return sorted(builtins)
    for hpp in BUILTINS_DIR.glob("*.hpp"):
        content = read_file(hpp)
        # Match registry.register("name", ...) patterns
        for m in re.finditer(r'register\s*\(\s*"(\w+)"', content):
            builtins.add(m.group(1))
        # Also match table["name"] = ... patterns
        for m in re.finditer(r'table\s*\[\s*"(\w+)"\s*\]', content):
            builtins.add(m.group(1))
    return sorted(builtins)


# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# 2. CLASSIFY EXTRACTED DATA
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

CONTROL_KEYWORDS = {"if", "elif", "else", "for", "while"}
LOOP_KEYWORDS = {"in", "range"}
IMPORT_KEYWORDS = {"bring", "from", "as"}
DECL_KEYWORDS = {"fn", "give", "of"}
LOGICAL_WORD_OPS = {"and", "or", "not"}
COMPARISON_WORD_OPS = {"is", "eq", "ne", "gt", "lt", "ge", "le"}
CONSTANTS = {"true", "false", "none"}

IO_BUILTINS = {"print", "assert"}
TYPE_BUILTINS = {"type", "str", "num", "len"}
COLLECTION_BUILTINS = {"push", "pop", "keys", "values", "range", "set", "has"}
MATH_BUILTINS = {"floor", "ceil", "round", "abs", "mod"}
OS_BUILTINS = {
    "mkdir", "rm", "cp", "mv", "exists", "is_file", "is_dir", "ls",
    "read", "write", "append", "file_size", "cwd", "cd",
    "abspath", "basename", "dirname", "ext",
    "env_get", "env_set", "env_unset", "env_has",
    "run", "run_capture", "pid"
}


# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# 3. GENERATE TMLANGUAGE JSON
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

def word_alt(words):
    """Build a \\b(word1|word2|...)\\b alternation."""
    return "\\b(" + "|".join(sorted(words, key=lambda w: (-len(w), w))) + ")\\b"


def build_tmlanguage(keywords, builtins):
    """Build the complete tmLanguage JSON for Xell."""
    grammar = OrderedDict()
    grammar["$schema"] = "https://raw.githubusercontent.com/martinring/tmlanguage/master/tmlanguage.json"
    grammar["name"] = "Xell"
    grammar["scopeName"] = "source.xell"
    grammar["fileTypes"] = ["xel", "nxel"]
    grammar["comment"] = (
        "AUTO-GENERATED by gen_grammar.py — DO NOT EDIT MANUALLY. "
        "Change the parser sources and re-run: python3 Extensions/gen_grammar.py"
    )

    grammar["patterns"] = [
        {"include": "#block-comment"},
        {"include": "#line-comment"},
        {"include": "#strings"},
        {"include": "#function-definition"},
        {"include": "#for-loop"},
        {"include": "#for-in-loop"},
        {"include": "#bring-statement"},
        {"include": "#control-keywords"},
        {"include": "#declaration-keywords"},
        {"include": "#import-keywords"},
        {"include": "#logical-operators"},
        {"include": "#comparison-word-operators"},
        {"include": "#boolean-constants"},
        {"include": "#none-constant"},
        {"include": "#io-builtins"},
        {"include": "#type-builtins"},
        {"include": "#collection-builtins"},
        {"include": "#math-builtins"},
        {"include": "#os-builtins"},
        {"include": "#arrow-access"},
        {"include": "#comparison-operators"},
        {"include": "#assignment-operator"},
        {"include": "#arithmetic-operators"},
        {"include": "#numbers"},
        {"include": "#function-call"},
        {"include": "#semicolon-terminator"},
        {"include": "#dot-terminator"},
        {"include": "#punctuation"},
        {"include": "#identifiers"},
    ]

    repo = OrderedDict()

    # Comments
    repo["block-comment"] = {
        "name": "comment.block.arrow.xell",
        "begin": "-->",
        "end": "<--",
        "beginCaptures": {"0": {"name": "punctuation.definition.comment.begin.xell"}},
        "endCaptures": {"0": {"name": "punctuation.definition.comment.end.xell"}},
    }
    repo["line-comment"] = {
        "name": "comment.line.number-sign.xell",
        "match": "#.*$",
    }

    # Strings with interpolation
    repo["strings"] = {
        "name": "string.quoted.double.xell",
        "begin": "\"",
        "end": "\"",
        "patterns": [
            {
                "name": "meta.interpolation.xell",
                "begin": "\\{",
                "end": "\\}",
                "beginCaptures": {"0": {"name": "punctuation.definition.interpolation.begin.xell"}},
                "endCaptures": {"0": {"name": "punctuation.definition.interpolation.end.xell"}},
                "patterns": [{"include": "source.xell"}]
            },
            {"name": "constant.character.escape.xell", "match": "\\\\."}
        ]
    }

    # Function definition
    repo["function-definition"] = {
        "patterns": [{
            "name": "meta.function.definition.xell",
            "begin": "\\b(fn)\\s+([a-zA-Z_][a-zA-Z0-9_]*)\\s*\\(",
            "beginCaptures": {
                "1": {"name": "keyword.declaration.function.xell"},
                "2": {"name": "entity.name.function.definition.xell"},
            },
            "end": "\\)",
            "patterns": [
                {
                    "name": "variable.parameter.xell",
                    "match": "\\b([a-zA-Z_][a-zA-Z0-9_]*)\\b"
                },
                {"name": "punctuation.separator.parameter.xell", "match": ","},
            ]
        }]
    }

    # For loop
    repo["for-loop"] = {
        "patterns": [{
            "match": "\\b(for)\\s+([a-zA-Z_][a-zA-Z0-9_]*)\\s+(in)\\s+(range)\\b",
            "captures": {
                "1": {"name": "keyword.control.flow.xell"},
                "2": {"name": "variable.other.loop.xell"},
                "3": {"name": "keyword.control.loop.xell"},
                "4": {"name": "support.function.builtin.xell"},
            }
        }]
    }

    # For-in loop
    repo["for-in-loop"] = {
        "patterns": [{
            "match": "\\b(for)\\s+([a-zA-Z_][a-zA-Z0-9_]*)\\s+(in)\\b",
            "captures": {
                "1": {"name": "keyword.control.flow.xell"},
                "2": {"name": "variable.other.loop.xell"},
                "3": {"name": "keyword.control.loop.xell"},
            }
        }]
    }

    # Bring statement
    repo["bring-statement"] = {
        "patterns": [{
            "match": "\\b(from)\\s+([a-zA-Z_][a-zA-Z0-9_]*)\\s+(bring)\\b",
            "captures": {
                "1": {"name": "keyword.control.import.xell"},
                "2": {"name": "entity.name.module.xell"},
                "3": {"name": "keyword.control.import.xell"},
            }
        }]
    }

    # Keywords
    repo["control-keywords"] = {
        "name": "keyword.control.flow.xell",
        "match": word_alt(CONTROL_KEYWORDS)
    }
    repo["declaration-keywords"] = {
        "name": "keyword.declaration.xell",
        "match": word_alt(DECL_KEYWORDS)
    }
    repo["import-keywords"] = {
        "name": "keyword.control.import.xell",
        "match": word_alt(IMPORT_KEYWORDS)
    }
    repo["logical-operators"] = {
        "name": "keyword.operator.logical.xell",
        "match": word_alt(LOGICAL_WORD_OPS)
    }
    repo["comparison-word-operators"] = {
        "name": "keyword.operator.comparison.word.xell",
        "match": word_alt(COMPARISON_WORD_OPS)
    }

    # Constants
    repo["boolean-constants"] = {
        "name": "constant.language.boolean.xell",
        "match": "\\b(true|false)\\b"
    }
    repo["none-constant"] = {
        "name": "constant.language.none.xell",
        "match": "\\bnone\\b"
    }

    # Builtins by category
    repo["io-builtins"] = {
        "match": "\\b(" + "|".join(sorted(IO_BUILTINS)) + ")\\s*(?=\\()",
        "name": "support.function.io.xell"
    }
    repo["type-builtins"] = {
        "match": "\\b(" + "|".join(sorted(TYPE_BUILTINS)) + ")\\s*(?=\\()",
        "name": "support.function.type.xell"
    }
    repo["collection-builtins"] = {
        "match": "\\b(" + "|".join(sorted(COLLECTION_BUILTINS)) + ")\\s*(?=\\()",
        "name": "support.function.collection.xell"
    }
    repo["math-builtins"] = {
        "match": "\\b(" + "|".join(sorted(MATH_BUILTINS)) + ")\\s*(?=\\()",
        "name": "support.function.math.xell"
    }
    repo["os-builtins"] = {
        "match": "\\b(" + "|".join(sorted(OS_BUILTINS)) + ")\\s*(?=\\()",
        "name": "support.function.os.xell"
    }

    # Operators
    repo["arrow-access"] = {
        "name": "keyword.operator.access.xell",
        "match": "->"
    }
    repo["comparison-operators"] = {
        "name": "keyword.operator.comparison.xell",
        "match": "==|!=|<=|>=|<|>"
    }
    repo["assignment-operator"] = {
        "name": "keyword.operator.assignment.xell",
        "match": "="
    }
    repo["arithmetic-operators"] = {
        "name": "keyword.operator.arithmetic.xell",
        "match": "[+\\-*/%]"
    }

    # Numbers
    repo["numbers"] = {
        "name": "constant.numeric.xell",
        "match": "\\b\\d+(\\.\\d+)?\\b"
    }

    # Function call
    repo["function-call"] = {
        "match": "\\b([a-zA-Z_][a-zA-Z0-9_]*)\\s*(?=\\()",
        "captures": {"1": {"name": "entity.name.function.call.xell"}}
    }

    # Terminators
    repo["semicolon-terminator"] = {
        "name": "punctuation.terminator.block.xell",
        "match": ";"
    }
    repo["dot-terminator"] = {
        "name": "punctuation.terminator.statement.xell",
        "match": "\\."
    }

    # Punctuation
    repo["punctuation"] = {
        "patterns": [
            {"name": "punctuation.definition.scope.open.xell", "match": ":"},
            {"name": "punctuation.bracket.round.xell", "match": "[()]"},
            {"name": "punctuation.bracket.square.xell", "match": "[\\[\\]]"},
            {"name": "punctuation.bracket.curly.xell", "match": "[{}]"},
            {"name": "punctuation.separator.comma.xell", "match": ","},
        ]
    }

    # Identifiers
    repo["identifiers"] = {
        "name": "variable.other.xell",
        "match": "\\b[a-zA-Z_][a-zA-Z0-9_]*\\b"
    }

    grammar["repository"] = repo
    return grammar


# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# 4. MAIN
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

def main():
    check_mode = "--check" in sys.argv

    # Read sources
    if TOKEN_HPP.exists():
        token_src = read_file(TOKEN_HPP)
        keywords = extract_keywords(token_src)
    else:
        print(f"Warning: {TOKEN_HPP} not found, using defaults")
        keywords = []

    builtins = extract_builtins_from_files()

    print(f"[gen_grammar] Keywords: {keywords}")
    print(f"[gen_grammar] Builtins: {builtins}")

    # Generate grammar
    grammar = build_tmlanguage(keywords, builtins)
    new_json = json.dumps(grammar, indent=2) + "\n"

    if check_mode:
        if TMLANG_OUT.exists():
            existing = read_file(TMLANG_OUT)
            if existing == new_json:
                print("[gen_grammar] ✓ Grammar is up-to-date")
                sys.exit(0)
            else:
                print("[gen_grammar] ✗ Grammar is out-of-date — run gen_grammar.py to update")
                sys.exit(1)
        else:
            print(f"[gen_grammar] ✗ {TMLANG_OUT} not found")
            sys.exit(1)
    else:
        TMLANG_OUT.parent.mkdir(parents=True, exist_ok=True)
        with open(TMLANG_OUT, "w") as f:
            f.write(new_json)
        print(f"[gen_grammar] ✓ Wrote {TMLANG_OUT}")


if __name__ == "__main__":
    main()
